---
title: "Phylogenetic meta-analyses"
author: "Gergely Horváth"
date: '13.06.2023.'
output: pdf_document
classoption: landscape
---

Analyses are based on codes provided by Farquharson et al. 2018. Nat Commun 9: 1055; Mitchell et al. 2021. Ecol Evol 11: 7201-7210; and Winternitz et al. 2017. Mol Ecol 26: 668-688.

# Starting steps, summary of dataset

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
library(MCMCglmm); library(metafor); library(ape); library(Matrix);
library(rotl); library(rmeta); library(forestplot); library(rncl);
library(Hmisc); library(mice); library(lattice); library(HDInterval);
library(meta); library(readxl)
```

```{r,echo=FALSE}
xdata <- read_excel("data/case_studies/Metadata_ALL_NEWER.xlsx")
xdata$N_OBS<-as.numeric(xdata$N_OBS)
xdata$N_ID<-as.numeric(xdata$N_ID)
xdata$N_rep_mean<-as.numeric(xdata$N_rep_mean)
xdata$ES.ID<-as.factor(xdata$ES.ID)
xdata$scientific.name <- tolower(as.factor(xdata$scientific.name))
xdata$species<-as.factor(xdata$species)
xdata$taxa <- as.factor(xdata$taxa)
xdata$study <- as.factor(xdata$study)
xdata$behaviour <-as.factor(xdata$behaviour)
xdata$environment <-as.factor(xdata$environment)
xdata$measures.use<-as.factor(xdata$measures.use)
xdata$age <- as.factor(xdata$age)
xdata$sex <- as.factor(xdata$sex)
xdata$temporal.context <- as.factor(xdata$temporal.context)
```

We are going to analyse the general association between behavioural type (i.e., individual behavioural mean) and behavioural predictability. To do this, we have to transform correlation coefficients to Fisher’s normalized correlation coefficients (Zr) $$ Zr = \frac{1}{2} * ln\left(\frac{1+\rho}{1-\rho}\right) $$.

```{r,results='hide'}
Zr.corr<-function(r){
	Zr<-0.5*log((1+r)/(1-r))
	print(Zr)}

xdata$yi.z<-Zr.corr(xdata$Corr)
```

Lower risk-taking measures indicate risk-prone individuals (i.e. individuals with higher latency values are considered shyer). This also true for sheltering behaviour (see Sos et al., unpublished study and Horváth et al., unpublished study #2). Thus, We have to multiply these Zr values by -1 to make positive correlations equate risk-prone animals being more variable

```{r}
xdata$yi.z[xdata$measures.use == 'latency']<-xdata$yi.z[xdata$measures.use == 'latency']*-1
```

sampling variance is generated by $$ variance = \frac{N~mean.repeats}{\left(2*(N~individual-2)*(N~mean.repeats-1)\right)} $$

```{r, results='hide'}
vi<-xdata$N_rep_mean/(2*(xdata$N_ID-2)*(xdata$N_rep_mean-1))

xdata<-data.frame(xdata,vi)
```

\newpage
Let's take a look on the data. We have 93 estimates coming from 58 studies and 44 species

```{r, echo=FALSE}
levels(xdata$study)
```

\newpage

We can see, that there are more than twice as many studies on vertebrates as on invertebrate taxa (40 *vs.* 18, respectively). All but two papers focused on a single species (Harrison et al. 2019 provide data on five different species of fish, while Toscano et al. 2023 studied two gastropod species.), but some species are targeted by multiple studies: guppies are represented by 11 estimates from six studies (five different labs), there are five estimates on carpetan rock lizards from three studies (all authored by Horváth et al.), four estimates on hermit crabs from three studies (three different labs), four estimates on pill bugs from three studies (two separate labs), four estimates on sticklebacks from three different studies (separate labs), four estimates on dunnocks from three studies (all authored by Holtmann et al.), three estimates on agile frogs from two studies (published by the same lab), two estimates of zebrafish from two studies (separate labs), two estimates of eastern mosquitofish from two studies (separate labs), and two estimates of periwinkles from two separate studies authored by Cornwell et al.

```{r,echo = FALSE}
levels(xdata$species)
```

\newpage
## Phylogenetic tree

We are creating the phylogenetic tree based on published phylogenies available through the 'Open Tree of Life' (Hincliff et al. 2015) via the package `rotl`. The plot (including specific names) appears in the ESM as Supplementary Figure S2.

```{r,warning=FALSE, message=FALSE, fig.show='hide'}
species <- unique(xdata$scientific.name)
species <- as.data.frame(species)

species[,1] <- as.character(species[,1])

taxa <- tnrs_match_names(unique(xdata$scientific.name), context="Animals")
taxon_map <- structure(taxa$search_string, names=taxa$unique_name)
tr<-tol_induced_subtree(ott_id(taxa)[is_in_tree(ott_id(taxa))])
#saveRDS(tr,"phylotree.rds")
tr <- readRDS("phylotree.rds")

plot(tr, show.tip.label = FALSE)
```

The tree contains node labels for nodes that match a higher taxonomic group, so we will remove extra information from the tip labels

```{r,warning=FALSE,message=FALSE,results='hide'}
otl_tips <- strip_ott_ids(tr$tip.label, remove_underscores=TRUE)
tr$tip.label <- taxon_map[ otl_tips ]

any(duplicated(tr$node.label))
tr$node.label <- NULL

xdata <- xdata[xdata$scientific.name %in% tr$tip.label, ]
```

The phylogenetic variance-covariance matrix will be created in multiple steps. First, we are going to rename column to 'animal' for input to MCMCglmm.

```{r}
xdata$animal <- xdata$scientific.name
```

\newpage

Next, we'll compute branch lengths using ape package default based on topology and match matrix to the dataset.

```{r,fig.show='hide'}
CorMatrix <- vcv(compute.brlen(tr, corr = T))

CorExt <- as.matrix(CorMatrix[match(xdata$animal, rownames(CorMatrix)), match(xdata$animal, colnames(CorMatrix))])
levelplot(CorMatrix, xlab = '', ylab = 'Species')
```

MCMCglmm requires inverse matrix for input.

```{r}
Cinv <- solve(CorMatrix)
Cinv2 <- as(Cinv, "dgCMatrix")
```

Lastly, MCMCglmm also requires variances as input - we have no random structure specified for variances.

```{r}
MEV <- xdata$vi
```

\newpage
# Hierarchical modelling

Now we can start to build our models. We will apply a multi-level meta-analytic approach to estimate effect sizes to estimate sizes. First, we will ran intercept-only mixed models to determine the mean effect size across all studies.

```{r,message=FALSE, warning=FALSE, results='hide'}
a <- 1000

prior.null <- list(R=list(V=1,nu=0.002),
		  G=list(G1=list(V=diag(1),fix=1)))

model.null <- MCMCglmm(yi.z~1, mev=MEV,data=xdata, nitt=3000000,
                   thin=500, burnin=1000000, verbose=T, prior=prior.null, pr=T)

#saveRDS(model.null,"nullmodel.rds")
model.null <- readRDS("nullmodel.rds")

```

```{r}
summary(model.null)
```

After checking whether a series of models fitted with alternative random factors improve the model fit, we parameterize a 'full model' with 'phylogeny', 'species.ID', 'study.ID' and 'effect size.ID' as random factors. Most of the studies have multiple estimates either because measured multiple traits (Beyts et al. 2023 Behav Ecol; Brand et al. 2023 Behav Ecol; Bucklaew and Dochtermann 2021 Ethology;  Ferderer et al. 2020 Anim Behav; Fürtbauer et al. 2015 Funct Ecol; Holtmann et al. 2021 J Evol Biol; Horváth et al. 2016 Ethology; Houslay et al. 2018 Funct Ecol; Kurvers et al. 2018 Sci Rep; O'Dea et al. 2022 Methods Ecol Evol; Polverino et al. 2019 J R Soc Interface; Sakai 2020 Anim Behav; Urszán et al. 2018 J Anim Ecol; Wexler et al. 2016 Behav Ecol Sociobiol) or because having multiple subpopulations, treatments or species (Bridger et al. 2015 Proc R Soc B; Harrison et al. 2019 Behav Ecol; Herczeg et al. 2019 J Evol Biol; Gervais et al. 2020 J Evol Biol; Maskrey et al. 2020 J Anim Ecol; Horváth et al., unpublished study #1; Santostefano et al. 2017 Proc R Soc B; Sztruhala et al., unpublished study; Thoré et al. 2017 PeerJ).

```{r, message=FALSE, warning=FALSE,results='hide'}
prior.full <- list(R=list(V=1,nu=0.002),
			             G=list(G1=list(V = diag(1), nu = 1, alpha.mu = 0, alpha.V = diag(1)*a),
			             G2=list(V = diag(1), nu = 1, alpha.mu = 0, alpha.V = diag(1)*a),
			             G3=list(V = diag(1), nu = 1, alpha.mu = 0, alpha.V = diag(1)*a),
			             G4=list(V = diag(1), nu = 1, alpha.mu = 0, alpha.V = diag(1)*a)))

model.full<-MCMCglmm(yi.z ~ 1, random = ~ animal + study + species + ES.ID, 
                     mev = MEV, data = xdata, nitt=3000000, thin=500, burnin=1000000, 
                     verbose=T, prior=prior.full, pr=T, ginverse=list(animal=Cinv2))

#saveRDS(model.full,"phylogenetic_model_full.rds")
model.full <- readRDS("phylogenetic_model_full.rds")
```

```{r}
summary(model.full)
```

\newpage
## Heterogeneity statistics

In addition to partitioning total variance into phylogenetic variation and variation across studies, we also included species.ID and effect size.ID. The reason behind this is that phylogeny accounts only for non-independence due to shared evolutionary history, while species.ID accounts for other sources of non-independence arising from effect sizes coming from the same species, in the same time, effect size.ID allows us for variation in effects across individual effect sizes. 

```{r}
Weight<-1/xdata$vi
MV<-sum(Weight*(length(Weight)-1))/(sum(Weight)^2-sum(Weight^2))
```

First, we will calculate residual I^2 for the null model

```{r}
I2r<-100*(model.null$VCV[,"units"])/(model.null$VCV[,"units"]+MV)
mean(I2r)
round(posterior.mode(I2r),4)
HPDinterval(I2r)
```

Next, we will calculate heterogeneity estimates for the full model

```{r}
# I2 total
I2t<-100*(model.full$VCV[,"units"]+model.full$VCV[,"animal"]+model.full$VCV[,"study"]+model.full$VCV[,"species"]+model.full$VCV[,"ES.ID"])/
            (model.full$VCV[,"animal"]+model.full$VCV[,"study"]+model.full$VCV[,"species"]+model.full$VCV[,"ES.ID"]+model.full$VCV[,"units"]+MV)
mean(I2t)
posterior.mode(I2t)
HPDinterval(I2t)
```

```{r}
# I2 phylogeny
I2p<-100*(model.full$VCV[,"animal"])/(model.full$VCV[,"animal"]+model.full$VCV[,"study"]+model.full$VCV[,"species"]+
                                        model.full$VCV[,"ES.ID"]+model.full$VCV[,"units"]+MV)
mean(I2p)
posterior.mode(I2p)
HPDinterval(I2p)
```

```{r}
# I2 study.ID
I2st<-100*(model.full$VCV[,"study"])/(model.full$VCV[,"animal"]+model.full$VCV[,"study"]+model.full$VCV[,"species"]+
                                        model.full$VCV[,"ES.ID"]+model.full$VCV[,"units"]+MV)
mean(I2st)
posterior.mode(I2st)
HPDinterval(I2st)
```

```{r}
# I2 species.ID
I2st<-100*(model.full$VCV[,"species"])/(model.full$VCV[,"animal"]+model.full$VCV[,"study"]+model.full$VCV[,"species"]+
                                          model.full$VCV[,"ES.ID"]+model.full$VCV[,"units"]+MV)
mean(I2st)
posterior.mode(I2st)
HPDinterval(I2st)
```

```{r}
# I2 effect size.ID
I2st<-100*(model.full$VCV[,"ES.ID"])/(model.full$VCV[,"animal"]+model.full$VCV[,"study"]+model.full$VCV[,"species"]+
                                        model.full$VCV[,"ES.ID"]+model.full$VCV[,"units"]+MV)
mean(I2st)
posterior.mode(I2st)
HPDinterval(I2st)
```

```{r}
# I2 residual
I2r<-100*(model.full$VCV[,"units"])/(model.full$VCV[,"animal"]+model.full$VCV[,"study"]+model.full$VCV[,"species"]+
                                       model.full$VCV[,"ES.ID"]+model.full$VCV[,"units"]+MV)
mean(I2r)
posterior.mode(I2r)
HPDinterval(I2r)
```

```{r}
# H2 (heritability or Lambda) for univariate model (intercept)
H2<-100*(model.full$VCV[,"animal"])/(model.full$VCV[,"animal"]+model.full$VCV[,"study"]+model.full$VCV[,"species"]+
                                       model.full$VCV[,"ES.ID"]+model.full$VCV[,"units"])
mean(H2)
round(posterior.mode(H2),4)
round(HPDinterval(H2),4)
```

It is clear that most of the variation is, not surprisingly, explained by differences among philogenetic history, while heterogeneity among studies is rather low.

\newpage
## Meta regression

In order to identify the most important moderators, we'll construct a series of meta-regression models (Nakagawa and Santos 2012). As our sample size is somewhat limited, we chose to avoid complex models, instead, we conducted univariate fixed-effect mixed models to estimate the mean effect size for each moderator separately (see Winternitz et al. 2017). Models with categorical moderators were run without the intercept to test each trait against no effect

```{r, warning=FALSE, message=FALSE, results='hide'}
mregmod.env <- MCMCglmm(yi.z ~ environment-1, random = ~ animal + study + species + ES.ID, 
                        mev = MEV, data = xdata, nitt=3000000, thin=500, burnin=1000000, 
                        verbose=T, prior=prior.full, pr=T, ginverse=list(animal=Cinv2))

mregmod.sex <- MCMCglmm(yi.z ~ sex-1, random = ~ animal + study + species + ES.ID, 
                        mev = MEV, data = xdata, nitt=3000000, thin=500, burnin=1000000, 
                        verbose=T, prior=prior.full, pr=T, ginverse=list(animal=Cinv2))

mregmod.age <- MCMCglmm(yi.z ~ age-1, random = ~ animal + study + species + ES.ID, 
                        mev = MEV, data = xdata, nitt=3000000, thin=500, burnin=1000000, 
                        verbose=T, prior=prior.full, pr=T, ginverse=list(animal=Cinv2))

mregmod.behaviour <- MCMCglmm(yi.z ~ behaviour-1, random = ~ animal + study + species + ES.ID, 
                              mev = MEV, data = xdata, nitt=3000000, thin=500, burnin=1000000, 
                              verbose=T, prior=prior.full, pr=T, ginverse=list(animal=Cinv2))

mregmod.taxa <- MCMCglmm(yi.z ~ taxa-1, random = ~ animal + study + species + ES.ID, 
                         mev = MEV, data = xdata, nitt=3000000, thin=500, burnin=1000000, 
                         verbose=T, prior=prior.full, pr=T, ginverse=list(animal=Cinv2))

mregmod.temporal <- MCMCglmm(yi.z ~ temporal.context-1, random = ~ animal + study + species + ES.ID, 
                             mev = MEV, data = xdata, nitt=3000000, thin=500, burnin=1000000, 
                             verbose=T, prior=prior.full, pr=T, ginverse=list(animal=Cinv2))

#saveRDS(mregmod.env,"mregmod_env.rds")
mergmod.env <- readRDS("mregmod_env.rds")

#saveRDS(mregmod.sex,"mregmod_sex.rds")
mergmod.sex <- readRDS("mregmod_sex.rds")

#saveRDS(mregmod.age,"mregmod_age.rds")
mergmod.age <- readRDS("mregmod_age.rds")

#saveRDS(mregmod.behaviour,"mregmod_behaviour.rds")
mergmod.behaviour <- readRDS("mregmod_behaviour.rds")

#saveRDS(mregmod.taxa,"mregmod_taxa.rds")
mergmod.taxa <- readRDS("mregmod_taxa.rds")

#saveRDS(mregmod.temporal,"mregmod_temporal.rds")
mergmod.temporal <- readRDS("mregmod_temporal.rds")
```

```{r}
summary(mregmod.env)
mean(mregmod.env$Sol[,1:3])
posterior.mode(mregmod.env$Sol[,1:3])
```

```{r}
summary(mregmod.sex)
mean(mregmod.sex$Sol[,1:4])
posterior.mode(mregmod.sex$Sol[,1:4])
```

```{r}
summary(mregmod.age)
mean(mregmod.age$Sol[,1:4])
posterior.mode(mregmod.age$Sol[,1:4])
```

```{r}
summary(mregmod.behaviour)
mean(mregmod.behaviour$Sol[,1:2])
posterior.mode(mregmod.behaviour$Sol[,1:2])
```

```{r}
summary(mregmod.taxa)
mean(mregmod.taxa$Sol[,1:2])
posterior.mode(mregmod.taxa$Sol[,1:2])
```

```{r}
summary(mregmod.temporal)
mean(mregmod.temporal$Sol[,1:5])
posterior.mode(mregmod.temporal$Sol[,1:5])
```

Let's check the pairwise contrast p-values across different levels of moderator variables

```{r}
#Environment
p1<-min(sum(mregmod.env$Sol[,"environmentlab"] > mregmod.env$Sol[,"environmentnatural"])/
          length(mregmod.env$Sol[,1]),1-(sum(mregmod.env$Sol[,"environmentlab"] > mregmod.env$Sol[,"environmentnatural"])/
                                                      length(mregmod.env$Sol[,1])))
p2<-min(sum(mregmod.env$Sol[,"environmentlab"] > mregmod.env$Sol[,"environmentseminatural"])/
          length(mregmod.env$Sol[,1]), 1-(sum(mregmod.env$Sol[,"environmentlab"] > mregmod.env$Sol[,"environmentseminatural"])/
                                                      length(mregmod.env$Sol[,1])))
p3<-min(sum(mregmod.env$Sol[,"environmentnatural"] > mregmod.env$Sol[,"environmentseminatural"])/
          length(mregmod.env$Sol[,1]), 1-(sum(mregmod.env$Sol[,"environmentnatural"] > mregmod.env$Sol[,"environmentseminatural"])/
                                                      length(mregmod.env$Sol[,1])))
p1
p2
p3
```

```{r}
#Sex
p4<-min(sum(mregmod.sex$Sol[,"sexfemale"] > mregmod.sex$Sol[,"sexmale"])/
          length(mregmod.sex$Sol[,1]),1-(sum(mregmod.sex$Sol[,"sexfemale"] > mregmod.sex$Sol[,"sexmale"])/
                                                      length(mregmod.sex$Sol[,1])))
p5<-min(sum(mregmod.sex$Sol[,"sexfemale"] > mregmod.sex$Sol[,"sexmixed"])/
          length(mregmod.sex$Sol[,1]), 1-(sum(mregmod.sex$Sol[,"sexfemale"] > mregmod.sex$Sol[,"sexmixed"])/
                                                      length(mregmod.sex$Sol[,1])))
p6<-min(sum(mregmod.sex$Sol[,"sexfemale"] > mregmod.sex$Sol[,"sexunknown"])/
          length(mregmod.sex$Sol[,1]), 1-(sum(mregmod.sex$Sol[,"sexfemale"] > mregmod.sex$Sol[,"sexunknown"])/
                                                      length(mregmod.sex$Sol[,1])))
p7<-min(sum(mregmod.sex$Sol[,"sexmale"] > mregmod.sex$Sol[,"sexmixed"])/
          length(mregmod.sex$Sol[,1]), 1-(sum(mregmod.sex$Sol[,"sexmale"] > mregmod.sex$Sol[,"sexmixed"])/
                                                      length(mregmod.sex$Sol[,1])))
p8<-min(sum(mregmod.sex$Sol[,"sexmale"] > mregmod.sex$Sol[,"sexunknown"])/
          length(mregmod.sex$Sol[,1]), 1-(sum(mregmod.sex$Sol[,"sexmale"] > mregmod.sex$Sol[,"sexunknown"])/
                                                      length(mregmod.sex$Sol[,1])))
p4
p5
p6
p7
p8
```

```{r}
#Age
p9<-min(sum(mregmod.age$Sol[,"ageadult"] > mregmod.age$Sol[,"agejuvenile"])/
          length(mregmod.age$Sol[,1]), 1-(sum(mregmod.age$Sol[,"ageadult"] > mregmod.age$Sol[,"agejuvenile"])/
                                                      length(mregmod.age$Sol[,1])))
p10<-min(sum(mregmod.age$Sol[,"ageadult"] > mregmod.age$Sol[,"agemixed"])/
          length(mregmod.age$Sol[,1]), 1-(sum(mregmod.age$Sol[,"ageadult"] > mregmod.age$Sol[,"agemixed"])/
                                                      length(mregmod.age$Sol[,1])))
p11<-min(sum(mregmod.age$Sol[,"ageadult"] > mregmod.age$Sol[,"ageunknown"])/
          length(mregmod.age$Sol[,1]), 1-(sum(mregmod.age$Sol[,"ageadult"] > mregmod.age$Sol[,"ageunknown"])/
                                                      length(mregmod.age$Sol[,1])))
p12<-min(sum(mregmod.age$Sol[,"agejuvenile"] > mregmod.age$Sol[,"agemixed"])/
          length(mregmod.age$Sol[,1]), 1-(sum(mregmod.age$Sol[,"agejuvenile"] > mregmod.age$Sol[,"agemixed"])/
                                                      length(mregmod.age$Sol[,1])))
p13<-min(sum(mregmod.age$Sol[,"agejuvenile"] > mregmod.age$Sol[,"ageunknown"])/
          length(mregmod.age$Sol[,1]), 1-(sum(mregmod.age$Sol[,"agejuvenile"] > mregmod.age$Sol[,"ageunknown"])/
                                                      length(mregmod.age$Sol[,1])))
p9
p10
p11
p12
p13
```

```{r}
#Behaviour
p14<-min(sum(mregmod.behaviour$Sol[,"behaviourACT"] > mregmod.behaviour$Sol[,"behaviourRISK"])/
          length(mregmod.taxa$Sol[,1]), 1-(sum(mregmod.behaviour$Sol[,"behaviourACT"] > mregmod.behaviour$Sol[,"behaviourRISK"])/
                                                      length(mregmod.taxa$Sol[,1])))
p14
```

```{r}
#Taxa
p15<-min(sum(mregmod.taxa$Sol[,"taxavertebrate"] > mregmod.taxa$Sol[,"taxainvertebrate"])/
          length(mregmod.taxa$Sol[,1]), 1-(sum(mregmod.taxa$Sol[,"taxavertebrate"] > mregmod.taxa$Sol[,"taxainvertebrate"])/
                                                    length(mregmod.taxa$Sol[,1])))
p15
```

```{r}
#Temporal context
p16<-min(sum(mregmod.temporal$Sol[,"temporal.contextone week"] > mregmod.temporal$Sol[,"temporal.context2-3 weeks"])/
          length(mregmod.temporal$Sol[,1]), 1-(sum(mregmod.temporal$Sol[,"temporal.contextone week"] > 
                                                     mregmod.temporal$Sol[,"temporal.context2-3 weeks"])/
                                                        length(mregmod.temporal$Sol[,1])))
p17<-min(sum(mregmod.temporal$Sol[,"temporal.contextone week"] > mregmod.temporal$Sol[,"temporal.contextone month"])/
          length(mregmod.temporal$Sol[,1]), 1-(sum(mregmod.temporal$Sol[,"temporal.contextone week"] > 
                                                     mregmod.temporal$Sol[,"temporal.contextone month"])/
                                                        length(mregmod.temporal$Sol[,1])))
p18<-min(sum(mregmod.temporal$Sol[,"temporal.contextone week"] > mregmod.temporal$Sol[,"temporal.contextseveral months"])/
          length(mregmod.temporal$Sol[,1]), 1-(sum(mregmod.temporal$Sol[,"temporal.contextone week"] > 
                                                     mregmod.temporal$Sol[,"temporal.contextseveral months"])/
                                                        length(mregmod.temporal$Sol[,1])))
p19<-min(sum(mregmod.temporal$Sol[,"temporal.contextone week"] > mregmod.temporal$Sol[,"temporal.contextone or more years"])/
          length(mregmod.temporal$Sol[,1]), 1-(sum(mregmod.temporal$Sol[,"temporal.contextone week"] > 
                                                     mregmod.temporal$Sol[,"temporal.contextone or more years"])/
                                                        length(mregmod.temporal$Sol[,1])))
p20<-min(sum(mregmod.temporal$Sol[,"temporal.context2-3 weeks"] > mregmod.temporal$Sol[,"temporal.contextone month"])/
          length(mregmod.temporal$Sol[,1]), 1-(sum(mregmod.temporal$Sol[,"temporal.context2-3 weeks"] > 
                                                     mregmod.temporal$Sol[,"temporal.contextone month"])/
                                                        length(mregmod.temporal$Sol[,1])))
p21<-min(sum(mregmod.temporal$Sol[,"temporal.context2-3 weeks"] > mregmod.temporal$Sol[,"temporal.contextseveral months"])/
          length(mregmod.temporal$Sol[,1]), 1-(sum(mregmod.temporal$Sol[,"temporal.context2-3 weeks"] > 
                                                     mregmod.temporal$Sol[,"temporal.contextseveral months"])/
                                                        length(mregmod.temporal$Sol[,1])))
p22<-min(sum(mregmod.temporal$Sol[,"temporal.context2-3 weeks"] > mregmod.temporal$Sol[,"temporal.contextone or more years"])/
          length(mregmod.temporal$Sol[,1]), 1-(sum(mregmod.temporal$Sol[,"temporal.context2-3 weeks"] > 
                                                     mregmod.temporal$Sol[,"temporal.contextone or more years"])/
                                                        length(mregmod.temporal$Sol[,1])))
p23<-min(sum(mregmod.temporal$Sol[,"temporal.contextone month"] > mregmod.temporal$Sol[,"temporal.contextseveral months"])/
          length(mregmod.temporal$Sol[,1]), 1-(sum(mregmod.temporal$Sol[,"temporal.contextone month"] > 
                                                     mregmod.temporal$Sol[,"temporal.contextseveral months"])/
                                                        length(mregmod.temporal$Sol[,1])))
p24<-min(sum(mregmod.temporal$Sol[,"temporal.contextone month"] > mregmod.temporal$Sol[,"temporal.contextone or more years"])/
          length(mregmod.temporal$Sol[,1]), 1-(sum(mregmod.temporal$Sol[,"temporal.contextone month"] > 
                                                     mregmod.temporal$Sol[,"temporal.contextone or more years"])/
                                                        length(mregmod.temporal$Sol[,1])))
p25<-min(sum(mregmod.temporal$Sol[,"temporal.contextseveral months"] > mregmod.temporal$Sol[,"temporal.contextone or more years"])/
          length(mregmod.temporal$Sol[,1]), 1-(sum(mregmod.temporal$Sol[,"temporal.contextseveral months"] > 
                                                     mregmod.temporal$Sol[,"temporal.contextone or more years"])/
                                                        length(mregmod.temporal$Sol[,1])))
p16
p17
p18
p19
p20
p21
p22
p23
p24
p25
```

We can see now that none of the moderator variables have significant effect.

\newpage
# Randomization

In this final step we are going to generate random numbers with the original sample size for each correlation, from which we calculated absolute effect sizes. Then, we implemented the meta-analyses on the simulated effect sizes (all unsigned) to calculate absolute effect sizes for the null hypothesis by relying on the same model design as for the real data (see also Szász et al. 2019 Oikos 128: 1-12). The procedure will be repeated 1000 times to get a null distribution, against which the significance of the absolute effect sizes of the real data will be assessed.

Let's define a `model.full.abs` using the absolute values of the original `yi.z`

```{r,message=FALSE,warning=FALSE,results='hide'}
xdata$abs.yi.z<-abs(xdata$yi.z)

model.full.abs<-MCMCglmm(abs.yi.z ~ 1, random = ~ animal + study + species + ES.ID, 
                     mev = MEV, data = xdata, nitt=3000000, thin=500, burnin=1000000, 
                     verbose=T, prior=prior.full, pr=T, ginverse=list(animal=Cinv2))

#saveRDS(model.full.abs,"phylogenetic_model_full_abs.rds")
model.full.abs <- readRDS("phylogenetic_model_full_abs.rds")
```

```{r}
summary(model.full.abs)
```

```{r, message=FALSE, warning=FALSE, results='hide'}
iter=1000
reff=data.frame()
repeat{
        for (i in 1:nrow(xdata)) {
        xdata[i,c("yi.z", "vi")]=escalc(measure="ZCOR", ri=abs(cor(rnorm(xdata[i,"N_ID"]),rnorm(xdata[i,"N_ID"]))), ni=xdata[i,"N_ID"])}
        meta.phylo=try(MCMCglmm(yi.z ~ 1, random = ~ animal + study + species + ES.ID , 
                                family = "gaussian", mev = xdata$MEV, ginverse=list(animal=Cinv2), 
                                nitt=10000,thin=10,burnin=5000, prior = prior.full, data = xdata, verbose=F))
    if(class(meta.phylo)[1]!="try-error") {reff.est=cbind(posterior.mode(meta.phylo$Sol), mean(meta.phylo$Sol)); reff=rbind(reff,reff.est)}
    if (length(reff[,1])==iter) break
    print(length(reff[,1]))
}
colnames(reff)=c("post.mode","post.mean"); rownames(reff)=c()
write.table(reff, file="rand_eff_bayesian.txt", row.names=F, col.names=T, sep="\t")


reff=read.table(file="rand_eff_bayesian.txt",header=T, sep="\t",fill=T, strip.white=T, dec = ".")
```

```{r}
sim.mean=mean(reff$post.mean)
sim.mean
```

```{r}
P.es=sum(reff$post.mean>c(mean(model.full.abs$Sol[,1])))/length(reff$post.mean)
P.es
```

```{r}
error=qt(0.975,df=length(reff$post.mean)-1)*sd(reff$post.mean)/sqrt(length(reff$post.mean))
error
```

```{r}
left=mean(reff$post.mean)-error
right=mean(reff$post.mean)+error
left
right
```

```{r, message=FALSE, warning=FALSE, results='hide'}
tiff("rand_eff_bayesian_iterationpred_all.tiff")
hist(reff$post.mean, xlim =c(0, 0.6), ylim=c(0, 350), main="", breaks=10, xlab="", ylab="", cex.lab=1.5)
abline(lty=2, lwd=2, v=mean(model.full.abs$Sol[,1]))
dev.off()
```